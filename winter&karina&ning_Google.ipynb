{"cells":[{"cell_type":"markdown","metadata":{"id":"JcIwUuRvZej8"},"source":["## Transfer Learning 을 이용한 Aespa 그룹의 멤버 Winter, karina, Ningning Classifier 생성\n","\n","  1. Google Image Crawling\n","  2. Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7wd8jJmYJaH"},"outputs":[],"source":["# 한글폰트 : 네이버 바른 고딕 설정\n","# 폰트 설치 완료후에 런타임 다시 시작\n","\n","!apt install fonts-nanum -y\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","\n","fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n","font = fm.FontProperties(fname=fontpath, size=10)\n","plt.rc('font', family='NanumBarunGothic')\n","matplotlib.font_manager._rebuild()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42MNfw3ZeLvl"},"outputs":[],"source":["# Drive mount\n","\n","import os, sys\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","my_path = '/content/notebooks'\n","os.symlink('/content/drive/MyDrive/Colab Notebooks/my_env', my_path)\n","sys.path.insert(0, my_path)"]},{"cell_type":"markdown","metadata":{"id":"0yO2g_j1aWAr"},"source":["# 1. 구글 이미지 크롤러를 이용한 학습 이미지 수집"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"neZgxcW2ou3E"},"outputs":[],"source":["from selenium import webdriver\n","from selenium.webdriver.common.keys import Keys\n","import time\n","from tqdm import tqdm\n","import urllib.request\n","import shutil"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peyJ9vwMZdHe"},"outputs":[],"source":["# 구글 이미지 크롤링을 위한 드라이버 설치\n","# 이 부분은 처음 한번만 실행하면 됌.\n","\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ol39p3ji5EB8"},"outputs":[],"source":["directory_list = [\n","    '/content/drive/MyDrive/Human_classification/custom_dataset/train/',\n","    '/content/drive/MyDrive/Human_classification/custom_dataset/val/',\n","    '/content/drive/MyDrive/Human_classification/custom_dataset/test/',\n","]\n","\n","# 초기 디렉토리 만들기\n","for directory in directory_list:\n","    if not os.path.isdir(directory):\n","        os.makedirs(directory)\n","\n","# 수집한 이미지를 학습 데이터와 평가 데이터로 구분하는 함수\n","def dataset_split(idol, train_cnt, val_cnt):\n","\n","    # 학습 및 평가 데이터셋 디렉토리 만들기\n","    for directory in directory_list:\n","        if not os.path.isdir(directory + '/' + idol):\n","            try:\n","                os.makedirs(directory + '/' + idol)\n","            except:\n","                print(\"error\")\n","\n","    # 학습 및 평가 데이터셋 준비하기\n","    cnt = 1\n","    for file_name in os.listdir('/content/drive/MyDrive/Human_classification/'+idol):\n","\n","      # val_cnt 이하는 Validation data로, val_cnt이상, train_cnt이하는 Train data로, 그 외에는 전부 Test data로 사용한다.\n","        if cnt < val_cnt:\n","            print(f'[Validation Dataset] {file_name}')\n","            shutil.move('/content/drive/MyDrive/Human_classification/'+ idol + '/' + file_name, '/content/drive/MyDrive/Human_classification/custom_dataset/val/' + idol + '/' + file_name)\n","        elif cnt < train_cnt:\n","            print(f'[Train Dataset] {file_name}')\n","            shutil.move('/content/drive/MyDrive/Human_classification/'+ idol + '/' + file_name, '/content/drive/MyDrive/Human_classification/custom_dataset/train/' + idol + '/' + file_name)\n","        else:\n","            print(f'[Test Dataset] {file_name}')\n","            shutil.move('/content/drive/MyDrive/Human_classification/'+ idol + '/' + file_name, '/content/drive/MyDrive/Human_classification/custom_dataset/test/' + idol + '/' + file_name)\n","        cnt += 1\n","    shutil.rmtree('/content/drive/MyDrive/Human_classification/'+idol) # 지정된 파일 및 하위 디렉토리 전부 삭제"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T6W-gQsNxINy"},"outputs":[],"source":["def createDirectory(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSError:\n","        print(\"Error: Failed to create the directory.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7-Gu58HjZ9Dl"},"outputs":[],"source":["def crawling_img(name):\n","    options = webdriver.ChromeOptions()\n","    options.add_argument('--headless')\n","    options.add_argument('--no-sandbox')\n","    options.add_argument('--disable-dev-shm-usage')\n","    driver = webdriver.Chrome('chromedriver', options=options)\n","    \n","    # 해당 url로 이동\n","    url = \"https://www.google.co.kr/imghp?hl=ko&ogbl\"\n","    driver.get(url)\n","\n","    # 검색창을 찾는 코드\n","    # 내가 원하는 요소를 클릭하거나 하는 거 찾을 때는 F12를 눌러 왼쪽 위 마우스로\n","    # 찾는 기능을 이용해서 class, name 을 확인한다.\n","\n","    elem = driver.find_element_by_name(\"q\")\n","      # name으로 찾는 방법 외에도, class 등 다른 방법도 사용 가능하다.\n","      # elem = driver.find_element_by_class(\"gLFyf gsfi\")\n","\n","    # 원하는 입력값 전송 - 원하는 검색어 검색\n","    elem.send_keys(name)\n","    elem.send_keys(Keys.RETURN) # 엔터키 입력\n","\n","    # 검색 후에 스크롤을 끝까지 다 내려서 일단 다 불러온다.\n","    SCROLL_PAUSE_TIME = 1\n","\n","    # 브라우저의 높이를 알아내서 last_height에 저장한다.\n","    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n","\n","    # 무한반복문\n","    while True:\n","        # Scroll down to bottom\n","        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","\n","        # Wait to load page\n","        time.sleep(SCROLL_PAUSE_TIME)\n","\n","        # 새로운 높이가 이전의 높이와 같다면 빠져나온다. 즉, 더이상 안내려가면\n","        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n","        if new_height == last_height:\n","            try:\n","                driver.find_element_by_css_selector(\".mye4qd\").click() # 결과더보기 누름\n","            except:\n","                break # 결과더보기 없으면 이제 무한반복을 멈춘다.\n","        last_height = new_height\n","\n","    # 작은 이미지 클릭\n","    images = driver.find_elements_by_css_selector(\".rg_i.Q4LuWd\")\n","      # 여러개의 요소를 리스트 해야하므로 elements 사용\n","      # css의 특성상 클래스의 띄어쓰기에 . 을 대신해서 넣는다.\n","      # [0].click() 은 가장 첫번째 요소를 끄집어내서 클릭하겠다는 의미\n","\n","    # Create directory\n","    dir = \"/content/drive/MyDrive/Human_classification/\" + name\n","    createDirectory(dir)\n","\n","    count = 1\n","    for image in images:\n","        try:\n","          image.click()\n","          time.sleep(2)\n","          # 큰 이미지 선택하여 이미지 다운할 수 있는 src 주소 받아오기\n","          imgUrl = driver.find_element_by_xpath('/html/body/div[3]/c-wiz/div[3]/div[2]/div[3]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[3]/div/a/img').get_attribute(\"src\")\n","          # imgUrl = driver.find_element_by_css_selector(\".n3VNCb\").get_attribute(\"src\")\n","\n","          # path = '/content/drive/MyDrive/Human_classification/' + name\n","\n","          urllib.request.urlretrieve(imgUrl, dir + '/' + str(count) + \".jpg\")\n","          # count는 숫자형이기 때문에 str로 string형으로 만들어 문자끼리 더해지게 한다.\n","          count = count + 1\n","          if count >= 300:  # 300장 다운 받으면 멈춘다.\n","              break\n","        except:\n","            pass\n","      \n","    driver.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZR_nsaOcak0"},"outputs":[],"source":["idol = '에스파 윈터'\n","crawling_img(idol)\n","dataset_split(idol, 270, 30)\n","# 1~30 : val\n","# 31~270 : train\n","# 271~300 : test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQrK3ljmDkUJ"},"outputs":[],"source":["idol = '에스파 카리나'\n","crawling_img(idol)\n","dataset_split(idol, 270, 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bOu_DFfjDkXJ"},"outputs":[],"source":["idol = '에스파 닝닝'\n","crawling_img(idol)\n","dataset_split(idol, 270, 30)"]},{"cell_type":"markdown","metadata":{"id":"S7acNKp1crpx"},"source":["#2. Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_h9aXIOecvw4"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torchvision\n","from torchvision import datasets, models, transforms\n","\n","import numpy as np\n","import time\n","\n","# colab에서 GPU사용\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체"]},{"cell_type":"markdown","metadata":{"id":"yBWyTs4FiFxm"},"source":["데이터 가공"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZH38cs3SdIs9"},"outputs":[],"source":["# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n","\n","# transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n","# transform.Normalize([R 평균, G 평균, B 평균], [R 표준편차, G 표준편차, B 표준편차])\n","# ImageNet과 유사할 경우 그 평균과 표준편차를 사용한다. [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","\n","transforms_train = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n","])\n","\n","transforms_val = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","transforms_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","data_dir = '/content/drive/MyDrive/Human_classification/custom_dataset'\n","train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n","val_datasets = datasets.ImageFolder(os.path.join(data_dir, 'val'), transforms_val)\n","test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'test'), transforms_test)\n","\n","train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=4)\n","val_dataloader = torch.utils.data.DataLoader(val_datasets, batch_size=4, shuffle=True, num_workers=4)\n","test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=4, shuffle=True, num_workers=4)\n","\n","print('train 데이터셋 크기:', len(train_datasets))\n","print('val 데이터셋 크기:', len(val_datasets))\n","print('test 데이터셋 크기:', len(test_datasets))\n","\n","class_names = train_datasets.classes\n","print('클래스:', class_names)"]},{"cell_type":"markdown","metadata":{"id":"xkyJg8hhiA32"},"source":["이미지 불러보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8iM26ZkdSGa"},"outputs":[],"source":["def imshow(input, title):\n","    # torch.Tensor를 numpy 객체로 변환\n","    input = input.numpy().transpose((1, 2, 0))\n","    # 이미지 정규화 해제하기\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    input = std * input + mean\n","    input = np.clip(input, 0, 1)\n","    # 이미지 출력\n","    plt.imshow(input)\n","    plt.title(title)\n","    plt.show()\n","\n","\n","# 학습 데이터를 배치 단위로 불러오기\n","iterator = iter(train_dataloader)\n","\n","# 현재 배치를 이용해 격자 형태의 이미지를 만들어 시각화\n","inputs, classes = next(iterator)\n","out = torchvision.utils.make_grid(inputs)\n","imshow(out, title=[class_names[x] for x in classes])"]},{"cell_type":"markdown","metadata":{"id":"UqU-VLZyiJKP"},"source":["Transfer Learning - Last layer train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMJrxHDchmzz"},"outputs":[],"source":["model = models.resnet34(pretrained=True)\n","num_features = model.fc.in_features\n","\n","# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 3개로 교체하여 마지막 레이어 다시 학습\n","model.fc = nn.Linear(num_features, 3)\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"]},{"cell_type":"markdown","metadata":{"id":"9L6X18Fniiq7"},"source":["Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_BYBpLPiPuh"},"outputs":[],"source":["num_epochs = 50\n","model.train()\n","start_time = time.time()\n","\n","# 전체 반복(epoch) 수 만큼 반복하며\n","for epoch in range(num_epochs):\n","    running_loss = 0.\n","    running_corrects = 0\n","\n","    # 배치 단위로 학습 데이터 불러오기\n","    for inputs, labels in train_dataloader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # 모델에 입력(forward)하고 결과 계산\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        loss = criterion(outputs, labels)\n","\n","        # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(train_datasets)\n","    epoch_acc = running_corrects / len(train_datasets) * 100.\n","\n","    # 학습 과정 중에 결과 출력\n","    print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))"]},{"cell_type":"code","source":["model.eval()\n","start_time = time.time()\n","\n","with torch.no_grad():\n","    running_loss = 0.\n","    running_corrects = 0\n","\n","    for inputs, labels in val_dataloader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        loss = criterion(outputs, labels)\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","\n","        # 한 배치의 첫 번째 이미지에 대하여 결과 시각화\n","        print(f'[예측 결과: {class_names[preds[0]]}] (실제 정답: {class_names[labels.data[0]]})')\n","        imshow(inputs.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n","\n","    epoch_loss = running_loss / len(val_datasets)\n","    epoch_acc = running_corrects / len(val_datasets) * 100.\n","    print('[Val Phase] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch_loss, epoch_acc, time.time() - start_time))"],"metadata":{"id":"3G6h7uxygqzu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"scv8PGrhnsgK"},"source":["Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOKiMA9uikRp"},"outputs":[],"source":["model.eval()\n","start_time = time.time()\n","\n","with torch.no_grad():\n","    running_loss = 0.\n","    running_corrects = 0\n","\n","    for inputs, labels in test_dataloader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        loss = criterion(outputs, labels)\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","\n","        # 한 배치의 첫 번째 이미지에 대하여 결과 시각화\n","        print(f'[예측 결과: {class_names[preds[0]]}] (실제 정답: {class_names[labels.data[0]]})')\n","        imshow(inputs.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n","\n","    epoch_loss = running_loss / len(test_datasets)\n","    epoch_acc = running_corrects / len(test_datasets) * 100.\n","    print('[Test Phase] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch_loss, epoch_acc, time.time() - start_time))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"winter&karina&ning_Google.ipynb","provenance":[],"authorship_tag":"ABX9TyMNo+TAVP9vbc/yjGBEeFj+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}